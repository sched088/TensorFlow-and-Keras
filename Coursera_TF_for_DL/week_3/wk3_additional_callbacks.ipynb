{"cells":[{"cell_type":"markdown","metadata":{"id":"cqcuv2G6iHsM"},"source":["# Additional callbacks\n","\n","In this reading we'll be looking at more of the inbuilt callbacks available in Keras."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"o_fM-3igiHsP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660852694548,"user_tz":300,"elapsed":6336,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}},"outputId":"28cf786e-9020-45ea-c095-ca53c284760f"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.2\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"GK55TJX7iHsQ"},"source":["We will again be using the sklearn diabetes dataset to demonstrate these callbacks."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"fViDbYEuiHsR","executionInfo":{"status":"ok","timestamp":1660852694904,"user_tz":300,"elapsed":358,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}}},"outputs":[],"source":["# Load the diabetes dataset\n","\n","from sklearn.datasets import load_diabetes\n","\n","diabetes_dataset = load_diabetes()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"C7uuEkDdiHsR","executionInfo":{"status":"ok","timestamp":1660852723812,"user_tz":300,"elapsed":159,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}}},"outputs":[],"source":["# Save the input and target variables\n","\n","from sklearn.model_selection import train_test_split\n","\n","data = diabetes_dataset['data']\n","targets = diabetes_dataset['target']"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"82j2vl7diHsS","executionInfo":{"status":"ok","timestamp":1660852724146,"user_tz":300,"elapsed":148,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}}},"outputs":[],"source":["# Split the data set into training and test sets\n","\n","train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size=0.1)"]},{"cell_type":"markdown","metadata":{"id":"SAbO1eL9iHsS"},"source":["Let's also build a simple model to fit to the data with our callbacks."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"mIRz6U_MiHsT","executionInfo":{"status":"ok","timestamp":1660852725472,"user_tz":300,"elapsed":346,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}}},"outputs":[],"source":["# Build the model\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","model = tf.keras.Sequential([\n","    Dense(128, activation='relu', input_shape=(train_data.shape[1],)),\n","    Dense(64,activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(1)        \n","])"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6C2h8WVpiHsT","executionInfo":{"status":"ok","timestamp":1660852726199,"user_tz":300,"elapsed":173,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}}},"outputs":[],"source":["# Compile the model\n","\n","model.compile(loss='mse',\n","                optimizer=\"adam\",metrics=[\"mse\",\"mae\"])"]},{"cell_type":"markdown","metadata":{"id":"790ZL87TiHsU"},"source":["Now onto the callbacks!"]},{"cell_type":"markdown","metadata":{"id":"B4km7YR5iHsU"},"source":["## Learning rate scheduler\n","\n","**Usage:** `tf.keras.callbacks.LearningRateScheduler(schedule, verbose=0)`\n","\n","The learning rate scheduler that we implemented in the previous reading as a custom callback is also available as a built in callback. \n","\n","As in our custom callback, the `LearningRateScheduler` in Keras takes a function `schedule` as an argument. \n","\n","This function `schedule` should take two arguments:\n","* The current epoch (as an integer), and\n","* The current learning rate,\n","\n","and return new learning rate for that epoch. \n","\n","The `LearningRateScheduler` also has an optional `verbose` argument, which prints information about the learning rate if it is set to 1.\n","\n","Let's see a simple example."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"e8yPd37DiHsV","executionInfo":{"status":"ok","timestamp":1660852734572,"user_tz":300,"elapsed":128,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}}},"outputs":[],"source":["# Define the learning rate schedule function\n","\n","def lr_function(epoch, lr):\n","    if epoch % 2 == 0:\n","        return lr\n","    else:\n","        return lr + epoch/1000"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"6CDFHhn2iHsV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660852738114,"user_tz":300,"elapsed":3104,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}},"outputId":"e9b098d2-b313-48dd-8380-d09e687094c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 0.0020000000474974513.\n","\n","Epoch 3: LearningRateScheduler setting learning rate to 0.0020000000949949026.\n","\n","Epoch 4: LearningRateScheduler setting learning rate to 0.005000000094994903.\n","\n","Epoch 5: LearningRateScheduler setting learning rate to 0.004999999888241291.\n","\n","Epoch 6: LearningRateScheduler setting learning rate to 0.009999999888241292.\n","\n","Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n","\n","Epoch 8: LearningRateScheduler setting learning rate to 0.01699999977648258.\n","\n","Epoch 9: LearningRateScheduler setting learning rate to 0.016999999061226845.\n","\n","Epoch 10: LearningRateScheduler setting learning rate to 0.025999999061226846.\n"]}],"source":["# Train the model\n","\n","history = model.fit(train_data, train_targets, epochs=10,\n","                    callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_function, verbose=1)], verbose=False)"]},{"cell_type":"markdown","metadata":{"id":"3mSuvdq3iHsV"},"source":["You can also use lambda functions to define your `schedule` given an epoch."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"0mDrwqBwiHsW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660852776377,"user_tz":300,"elapsed":887,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}},"outputId":"da2be583-d26c-4293-bf0d-a9832031a7f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1: LearningRateScheduler setting learning rate to 0.3333333333333333.\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 0.125.\n","\n","Epoch 3: LearningRateScheduler setting learning rate to 0.07692307692307693.\n","\n","Epoch 4: LearningRateScheduler setting learning rate to 0.05555555555555555.\n","\n","Epoch 5: LearningRateScheduler setting learning rate to 0.043478260869565216.\n","\n","Epoch 6: LearningRateScheduler setting learning rate to 0.03571428571428571.\n","\n","Epoch 7: LearningRateScheduler setting learning rate to 0.030303030303030304.\n","\n","Epoch 8: LearningRateScheduler setting learning rate to 0.02631578947368421.\n","\n","Epoch 9: LearningRateScheduler setting learning rate to 0.023255813953488372.\n","\n","Epoch 10: LearningRateScheduler setting learning rate to 0.020833333333333332.\n"]}],"source":["# Train the model with a difference schedule\n","\n","history = model.fit(train_data, train_targets, epochs=10,\n","                    callbacks=[tf.keras.callbacks.LearningRateScheduler(lambda x:1/(3+5*x), verbose=1)], \n","                    verbose=False)"]},{"cell_type":"markdown","metadata":{"id":"Urhuovq5iHsW"},"source":["## CSV logger\n","**Usage** `tf.keras.callbacks.CSVLogger(filename, separator=',', append=False)`\n","\n","This callback streams the results from each epoch into a CSV file.\n","The first line of the CSV file will be the names of pieces of information recorded on each subsequent line, beginning with the epoch and loss value. The values of metrics at the end of each epoch will also be recorded.\n","\n","The only compulsory argument is the `filename` for the log to be streamed to. This could also be a filepath.\n","\n","You can also specify the `separator` to be used between entries on each line.\n","\n","The `append` argument allows you the option to append your results to an existing file with the same name. This can be particularly useful if you are continuing training.\n","\n","Let's see an example."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"EW8pC6qWiHsW","executionInfo":{"status":"ok","timestamp":1660852899340,"user_tz":300,"elapsed":607,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}}},"outputs":[],"source":["# Train the model with a CSV logger\n","\n","history = model.fit(train_data, train_targets, epochs=10,\n","                    callbacks=[tf.keras.callbacks.CSVLogger(\"results.csv\")], verbose=False)"]},{"cell_type":"markdown","metadata":{"id":"5TV_4HNoiHsX"},"source":["Let's view the information in the CSV file we have created using `pandas`."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"VpA0KngviHsX","colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"status":"ok","timestamp":1660852899893,"user_tz":300,"elapsed":133,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}},"outputId":"7cfa9419-8ea4-49fd-9176-da3eb91935f0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["              loss        mae          mse\n","epoch                                     \n","0      2803.479492  42.672752  2803.479492\n","1      2791.484863  42.691383  2791.484863\n","2      2839.658936  42.779240  2839.658936\n","3      2771.892578  42.625813  2771.892578\n","4      2787.402344  42.669159  2787.402344\n","5      2794.852051  42.709698  2794.852051\n","6      2804.518311  42.297134  2804.518311\n","7      2760.208984  42.283390  2760.208984\n","8      2729.088379  41.969757  2729.088379\n","9      2754.585449  41.810867  2754.585449"],"text/html":["\n","  <div id=\"df-7464c8d0-9b1b-45a8-a2be-2b8140c7e110\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss</th>\n","      <th>mae</th>\n","      <th>mse</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2803.479492</td>\n","      <td>42.672752</td>\n","      <td>2803.479492</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2791.484863</td>\n","      <td>42.691383</td>\n","      <td>2791.484863</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2839.658936</td>\n","      <td>42.779240</td>\n","      <td>2839.658936</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2771.892578</td>\n","      <td>42.625813</td>\n","      <td>2771.892578</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2787.402344</td>\n","      <td>42.669159</td>\n","      <td>2787.402344</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2794.852051</td>\n","      <td>42.709698</td>\n","      <td>2794.852051</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2804.518311</td>\n","      <td>42.297134</td>\n","      <td>2804.518311</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2760.208984</td>\n","      <td>42.283390</td>\n","      <td>2760.208984</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2729.088379</td>\n","      <td>41.969757</td>\n","      <td>2729.088379</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2754.585449</td>\n","      <td>41.810867</td>\n","      <td>2754.585449</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7464c8d0-9b1b-45a8-a2be-2b8140c7e110')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7464c8d0-9b1b-45a8-a2be-2b8140c7e110 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7464c8d0-9b1b-45a8-a2be-2b8140c7e110');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["# Load the CSV\n","\n","import pandas as pd\n","\n","pd.read_csv(\"results.csv\", index_col='epoch')"]},{"cell_type":"markdown","metadata":{"id":"SZU7DrkJiHsX"},"source":["## Lambda callbacks\n","**Usage** `tf.keras.callbacks.LambdaCallback(\n","        on_epoch_begin=None, on_epoch_end=None, \n","        on_batch_begin=None, on_batch_end=None, \n","        on_train_begin=None, on_train_end=None)`\n","\n","Lambda callbacks are used to quickly define simple custom callbacks with the use of lambda functions.\n","\n","Each of the functions require some positional arguments.\n","* `on_epoch_begin` and `on_epoch_end` expect two arguments: `epoch` and `logs`,\n","* `on_batch_begin` and `on_batch_end` expect two arguments: `batch` and `logs` and\n","* `on_train_begin` and `on_train_end` expect one argument: `logs`.\n","\n","Let's see an example of this in practice."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"CLHqhOB_iHsX","executionInfo":{"status":"ok","timestamp":1660852964969,"user_tz":300,"elapsed":173,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}}},"outputs":[],"source":["# Print the epoch number at the beginning of each epoch\n","\n","epoch_callback = tf.keras.callbacks.LambdaCallback(\n","    on_epoch_begin=lambda epoch,logs: print('Starting Epoch {}!'.format(epoch+1)))"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"1gaQXb90iHsY","executionInfo":{"status":"ok","timestamp":1660852965284,"user_tz":300,"elapsed":150,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}}},"outputs":[],"source":["# Print the loss at the end of each batch\n","\n","batch_loss_callback = tf.keras.callbacks.LambdaCallback(\n","    on_batch_end=lambda batch,logs: print('\\n After batch {}, the loss is {:7.2f}.'.format(batch, logs['loss'])))"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"URS6mDmmiHsY","executionInfo":{"status":"ok","timestamp":1660852965435,"user_tz":300,"elapsed":2,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}}},"outputs":[],"source":["# Inform that training is finished\n","\n","train_finish_callback = tf.keras.callbacks.LambdaCallback(\n","    on_train_end=lambda logs: print('Training finished!'))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"il047_ipiHsY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660852966067,"user_tz":300,"elapsed":182,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}},"outputId":"2ed95bdb-4495-4b4d-fa86-4094e0b7c6d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Epoch 1!\n","\n"," After batch 0, the loss is 3090.12.\n","\n"," After batch 1, the loss is 3028.11.\n","\n"," After batch 2, the loss is 2870.13.\n","\n"," After batch 3, the loss is 2776.65.\n","Starting Epoch 2!\n","\n"," After batch 0, the loss is 2369.50.\n","\n"," After batch 1, the loss is 2476.27.\n","\n"," After batch 2, the loss is 2565.31.\n","\n"," After batch 3, the loss is 2675.63.\n","Starting Epoch 3!\n","\n"," After batch 0, the loss is 2389.94.\n","\n"," After batch 1, the loss is 2662.56.\n","\n"," After batch 2, the loss is 2592.74.\n","\n"," After batch 3, the loss is 2745.11.\n","Starting Epoch 4!\n","\n"," After batch 0, the loss is 2701.36.\n","\n"," After batch 1, the loss is 2719.25.\n","\n"," After batch 2, the loss is 2686.07.\n","\n"," After batch 3, the loss is 2667.36.\n","Starting Epoch 5!\n","\n"," After batch 0, the loss is 2851.07.\n","\n"," After batch 1, the loss is 2669.74.\n","\n"," After batch 2, the loss is 2656.43.\n","\n"," After batch 3, the loss is 2710.46.\n","Training finished!\n"]}],"source":["# Train the model with the lambda callbacks\n","\n","history = model.fit(train_data, train_targets, epochs=5, batch_size=100,\n","                    callbacks=[epoch_callback, batch_loss_callback,train_finish_callback], verbose=False)"]},{"cell_type":"markdown","metadata":{"id":"8S0OjZ5OiHsY"},"source":["## Reduce learning rate on plateau\n","**Usage** `tf.keras.callbacks.ReduceLROnPlateau(\n","            monitor='val_loss', \n","            factor=0.1, \n","            patience=10, \n","            verbose=0, \n","            mode='auto', \n","            min_delta=0.0001, \n","            cooldown=0, \n","            min_lr=0)`\n","\n","The `ReduceLROnPlateau` callback allows reduction of the learning rate when a metric has stopped improving. \n","The arguments are similar to those used in the `EarlyStopping` callback.\n","* The argument `monitor` is used to specify which metric to base the callback on.\n","* The `factor` is the factor by which the learning rate decreases i.e., new_lr=factor*old_lr.\n","* The `patience` is the number of epochs where there is no improvement on the monitored metric before the learning rate is reduced.\n","* The `verbose` argument will produce progress messages when set to 1.\n","* The `mode` determines whether the learning rate will decrease when the monitored quantity stops increasing (`max`) or decreasing (`min`). The `auto` setting causes the callback to infer the mode from the monitored quantity.\n","* The `min_delta` is the smallest change in the monitored quantity to be deemed an improvement.\n","* The `cooldown` is the number of epochs to wait after the learning rate is changed before the callback resumes normal operation.\n","* The `min_lr` is a lower bound on the learning rate that the callback will produce.\n","\n","Let's examine a final example."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"KdoQfUT8iHsZ","executionInfo":{"status":"ok","timestamp":1660852973048,"user_tz":300,"elapsed":1145,"user":{"displayName":"Maximilian Scheder-Bieschin","userId":"13808558721261695458"}}},"outputs":[],"source":["# Train the model with the ReduceLROnPlateau callback\n","\n","history = model.fit(train_data, train_targets, epochs=100, batch_size=100,\n","                    callbacks=[tf.keras.callbacks.ReduceLROnPlateau(\n","                        monitor=\"loss\",factor=0.2, verbose=1)], verbose=False)"]},{"cell_type":"markdown","metadata":{"id":"S6_VsxTgiHsZ"},"source":["### Further reading and resources\n","* https://keras.io/callbacks/\n","* https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler\n","* https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/CSVLogger\n","* https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LambdaCallback"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"wk3_additional_callbacks.ipynb","provenance":[{"file_id":"1JC780dIqlK4Moip1jJjRWn6ZiXdNYEST","timestamp":1660852670259}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}